# -*- coding: utf-8 -*-
"""python_opencv.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U3rMcGeLyYitZiUTMPl3_Ld3SgAJB2u2

# Introduction
This tutorial is to show using cloud based python environment to do open CV.
First we mount google drive space. 
We can put our input files there and use it to save output results.

# Setup & use google drive space
"""

# Commented out IPython magic to ensure Python compatibility.
#!pip uninstall opencv-python
#!pip uninstall opencv-contrib-python
#!pip install opencv-python
#!pip install opencv-contrib-python

import os
import numpy as np
from matplotlib import pyplot as plt
import cv2 as cv
import imutils
#from google.colab import drive
#from google.colab.patches import cv2_imshow
# feature_match()
class GoogleDrive:
    def __isnotebook(self):
        try:
            cfg = get_ipython().config
            # print(cfg)
            if 'google.colab' in cfg['IPKernelApp']['kernel_class']:
                from google.colab import drive
                from google.colab.patches import cv2_imshow
                get_ipython().magic('matplotlib inline')
                return True
            else:
                return False
        except NameError:
            return False

    def __init__(self):
        if self.__isnotebook():
            drive.mount('/content/gdrive', force_remount=True)
            work_dir = '/content/gdrive/My Drive/Colab Notebooks/py_code'
            # !rm - rf  '{work_dir}'
            # os.makedirs(work_dir, exist_ok=True)
            # !ls - ltra  '{work_dir}' /../ *.csv
            self.drive_path = work_dir + '/../'
        else:
            self.drive_path = ''

    def getDrivePath(self):
        return self.drive_path
    def isColabEnv(self):
        return self.__isnotebook()

    # commented out for desktop
    # def clone_repo(self):
    #     drive.mount('/content/gdrive', force_remount=True)
    #     work_dir = '/content/gdrive/My Drive/Colab Notebooks/py_code'
    #     !rm - rf
    #     '{work_dir}'
    #     os.makedirs(work_dir, exist_ok=True)
    #     !ls - ltra
    #     '{work_dir}' /../ *.ipynb
    #
    #     # %cd /content
    #
    #     # %rm -rf object_detection_demo
    #
    #     repo_url = 'https://github.com/wangxdflight/object_detection_demo'
    #     repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))
    #
    #     !git
    #     clone
    #     {repo_url}
    #     # %cd {repo_dir_path}
    #
    #     print('Pull it so that we have the latest code/data')
    #     !git
    #     pull
    #
    #     img_ref = cv.imread('/content/object_detection_demo/data/images/train/190.jpg')
    #     img = cv.imread('/content/object_detection_demo/data/images/train/skystones_2.jpg')
    #     img2 = cv.imread('/content/object_detection_demo/data/images/train/213.jpg')
    #     width, height = img.shape[:2]
    #     print('image size: ', width, height)
    #     # img = np.array(img, dtype=np.uint8)
    #
    #     """# Check environment setup
    #     Need to make sure the image sample files are avaible to use
    #     """
    #
    #     ! ls - lstr / content
    #     ! ls - lstr / content / object_detection_demo / data / images / train
    #     ! ls - lstr / content / object_detection_demo / data / raw / rings
    #
    #     """# Utilities"""

class Util:
    @staticmethod
    def whoami():
        import sys
        this_line_number = sys._getframe(1).f_lineno
        this_func_name = sys._getframe(1).f_code.co_name
        print("<<<function name:", this_func_name, ", line number:", this_line_number, ">>>")
        return

    @staticmethod
    def show_named_img(im):
        drv = GoogleDrive()
        if(drv.isColabEnv()):
            cv2_imshow(im)
        else:
            img = cv.imread(im)
            if (img.all() != None):
                plt.imshow(img)
                plt.title('ORIGINAL')
                plt.show()
            else:
                assert(0)
    @staticmethod
    def diplay_img_data(img):
        drv = GoogleDrive()
        if(drv.isColabEnv()):
            cv2_imshow(img)
        else:
            if (img.all() != None):
                RGB_img = cv.cvtColor(img, cv.COLOR_BGR2RGB)
                plt.imshow(RGB_img)
                #plt.title('ORIGINAL')
                plt.show()
            else:
                assert(0)
    @staticmethod
    def translate(image, x, y):
        M = np.float32([[1, 0, x], [0, 1, y]])
        shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))
        return shifted

    @staticmethod
    def rotate(image, angle, center=None, scale=1.0):
        (h, w) = image.shape[:2]

        if center is None:
            center = (w // 2, h // 2)

        M = cv2.getRotationMatrix2D(center, angle, scale)
        rotated = cv2.warpAffine(image, M, (w, h))

        return rotated

    @staticmethod
    def resize(image, newWidth=None, newHeight=None, inter=cv.INTER_AREA):
        # If conflicting width and height provided, the heigh will be used.
        height = image.shape[0]
        width = image.shape[1]

        if newWidth is None and newHeight is None:
            return image

        if newHeight is None:
            r = newWidth / width
            dim = (int(newWidth), int(int(height * newWidth) / int(width)))
        else:
            r = newHeight / height
            dim = (int(int(width * newHeight) / int(height)), int(newHeight))

        resized = cv.resize(image, dim, interpolation=cv.INTER_AREA)
        return resized

    @staticmethod
    def flip(image, mode):
        return cv.flip(image, mode)

    @staticmethod
    def crop(image, startCoord, endCoord):  # Inputs are 2 value tuples
        return image[startCoord[1]:endCoord[1], startCoord[0]:endCoord[0]]

    @staticmethod
    def changeBrightness(image, amount):
        M = np.ones(image.shape, dtype="uint8") * abs(amount)
        if amount >= 0:
            return cv.add(image, M)
        else:
            return cv.subtract(image, M)

    @staticmethod
    def removeBackground(image):
        """
        Purpose: Turns all non-orange pixels to black, removes all the noise to improve
        accuracy and consistency.
        Parameters: The image to manipulate
        Returns: The image with the background turned black
        """
        ringsOnlyImg = image.copy()  # Don't want to edit the original image
        imageHSV = cv.cvtColor(image, cv.COLOR_BGR2HSV)  # Convert to HSV to do hue detection

        print("BGR2HSV")
        Util.diplay_img_data(imageHSV)
        for r in range(0, imageHSV.shape[1] - 1):  # Loop through the width of the img
            for c in range(0, imageHSV.shape[0] - 1):  # Loop through the height of the img
                (hue, sat, val) = imageHSV[c, r]  # Get the HSV values of current pixel
                if hue < 10 or hue > 18 or sat < 80:  # If the hue value is not orange:
                    ringsOnlyImg[c, r] = (0, 0, 0)  # Set it to black
        return ringsOnlyImg  # Return image with black background

    @staticmethod
    def getEdges(image):
        """
        Purpose: return an image with a removed background and with edges detected.
        Parameters: the image to manipulate
        Returns: the image without the background and with the edges
        """
        # Turn all non-orange pixels black.
        ringsOnlyImg = Util.removeBackground(image)
        print("removed background")
        Util.diplay_img_data(ringsOnlyImg)

        # Turning into Greyscale and Blurring to prepare for edge detection and contouring
        blurred = cv.cvtColor(ringsOnlyImg, cv.COLOR_BGR2GRAY)
        blurred = cv.GaussianBlur(blurred, (5, 5), 0)
        print("blured")
        Util.diplay_img_data(blurred)

        # apply edge detection
        edged = cv.Canny(blurred, 100,
                         400)  # 2 threshold values have to be very high to ignore the gaps between rings, and irgnore other imperfections in the bg
        print("edged")
        Util.diplay_img_data(edged)
        return edged

    @staticmethod
    def SaltPepperNoise(edgeImg):
        count = 0
        lastMedian = edgeImg
        median = cv.medianBlur(edgeImg, 3)
        while not np.array_equal(lastMedian, median):
            zeroed = np.invert(np.logical_and(median, edgeImg))
            edgeImg[zeroed] = 0
            count = count + 1
            if count > 70:
                break
        lastMedian = median
        median = cv.medianBlur(edgeImg, 3)

    @staticmethod
    def findSignificantContour(edgeImg):
        contours, hierarchy = cv.findContours(
            edgeImg,
            cv.RETR_TREE,
            cv.CHAIN_APPROX_SIMPLE
        )
        # Find level 1 contours
        level1Meta = []
        for contourIndex, tupl in enumerate(hierarchy[0]):
            # Filter the ones without parent
            if tupl[3] == -1:
                tupl = np.insert(tupl.copy(), 0, [contourIndex])
                level1Meta.append(tupl)
        # From among them, find the contours with large surface area.
        contoursWithArea = []
        for tupl in level1Meta:
            contourIndex = tupl[0]
            contour = contours[contourIndex]
            area = cv.contourArea(contour)
            contoursWithArea.append([contour, area, contourIndex])
        contoursWithArea.sort(key=lambda meta: meta[1], reverse=True)
        largestContour = contoursWithArea[0][0]
        return largestContour

    @staticmethod
    def getEdges_new(img):  # https://medium.com/@chris.s.park/image-background-removal-using-opencv-part-1-da3695ac66b6
        img_resized = resize(img, newWidth=720)  # Ensure the image is 720 width so the crop will work
        img_cropped = crop(img_resized, (300, 220), (450, 330))  # Crop image to remove unecessary background noise
        g_blurred = cv.GaussianBlur(img_cropped, (5, 5), 0)
        print("blured")
        cv2_imshow(g_blurred)
        blurred_float = g_blurred.astype(np.float32) / 255.0
        edgeDetector = cv.ximgproc.createStructuredEdgeDetection("/content/object_detection_demo/data/raw/rings/model.yml")
        edges = edgeDetector.detectEdges(blurred_float) * 255.0
        print("edges")
        cv2_imshow(edges)
        edges_ = np.asarray(edges, np.uint8)
        SaltPepperNoise(edges_)
        print("salt pepper edges")
        cv2_imshow(edges_)
        contour = findSignificantContour(edges_)
        # Draw the contour on the original image
        contourImg = np.copy(img_cropped)
        cv.drawContours(contourImg, [contour], 0, (0, 255, 0), 2, cv.LINE_AA, maxLevel=1)
        print("drawContours")
        cv2_imshow(contourImg)


    """# Image thresholding"""

    @staticmethod
    def img_threshold(img):
        # img = cv.imread('/content/object_detection_demo/data/images/train/190.jpg',0)
        img = cv.medianBlur(img, 5)
        ret, th1 = cv.threshold(img, 127, 255, cv.THRESH_BINARY)
        th2 = cv.adaptiveThreshold(img, 255, cv.ADAPTIVE_THRESH_MEAN_C, \
                                   cv.THRESH_BINARY, 11, 2)
        th3 = cv.adaptiveThreshold(img, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, \
                                   cv.THRESH_BINARY, 11, 2)
        titles = ['Original Image', 'Global Thresholding (v = 127)',
                  'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']
        images = [img, th1, th2, th3]
        for i in range(4):
            plt.subplot(2, 2, i + 1), plt.imshow(images[i], 'gray')
            plt.title(titles[i])
            plt.xticks([]), plt.yticks([])
        plt.show()

    @staticmethod
    def otsu_threshold(img):
        # img = cv.imread('/content/object_detection_demo/data/images/train/190.jpg',0)
        # global thresholding
        ret1, th1 = cv.threshold(img, 127, 255, cv.THRESH_BINARY)
        # Otsu's thresholding
        ret2, th2 = cv.threshold(img, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)
        # Otsu's thresholding after Gaussian filtering
        blur = cv.GaussianBlur(img, (5, 5), 0)
        ret3, th3 = cv.threshold(blur, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)
        # plot all the images and their histograms
        images = [img, 0, th1,
                  img, 0, th2,
                  blur, 0, th3]
        titles = ['Original Noisy Image', 'Histogram', 'Global Thresholding (v=127)',
                  'Original Noisy Image', 'Histogram', "Otsu's Thresholding",
                  'Gaussian filtered Image', 'Histogram', "Otsu's Thresholding"]
        for i in range(3):
            plt.subplot(3, 3, i * 3 + 1), plt.imshow(images[i * 3], 'gray')
            plt.title(titles[i * 3]), plt.xticks([]), plt.yticks([])
            plt.subplot(3, 3, i * 3 + 2), plt.hist(images[i * 3].ravel(), 256)
            plt.title(titles[i * 3 + 1]), plt.xticks([]), plt.yticks([])
            plt.subplot(3, 3, i * 3 + 3), plt.imshow(images[i * 3 + 2], 'gray')
            plt.title(titles[i * 3 + 2]), plt.xticks([]), plt.yticks([])
        plt.show()


    def otsu2(img):
        # img = cv.imread('/content/object_detection_demo/data/images/train/190.jpg',0)
        blur = cv.GaussianBlur(img, (5, 5), 0)
        # find normalized_histogram, and its cumulative distribution function
        hist = cv.calcHist([blur], [0], None, [256], [0, 256])
        hist_norm = hist.ravel() / hist.sum()
        Q = hist_norm.cumsum()
        bins = np.arange(256)
        fn_min = np.inf
        thresh = -1
        for i in range(1, 256):
            p1, p2 = np.hsplit(hist_norm, [i])  # probabilities
            q1, q2 = Q[i], Q[255] - Q[i]  # cum sum of classes
            if q1 < 1.e-6 or q2 < 1.e-6:
                continue
            b1, b2 = np.hsplit(bins, [i])  # weights
            # finding means and variances
            m1, m2 = np.sum(p1 * b1) / q1, np.sum(p2 * b2) / q2
            v1, v2 = np.sum(((b1 - m1) ** 2) * p1) / q1, np.sum(((b2 - m2) ** 2) * p2) / q2
            # calculates the minimization function
            fn = v1 * q1 + v2 * q2
            if fn < fn_min:
                fn_min = fn
                thresh = i
        # find otsu's threshold value with OpenCV function
        ret, otsu = cv.threshold(blur, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)
        print("{} {}".format(thresh, ret))


    # #img = cv.imread('/content/object_detection_demo/data/images/train/190.jpg',0)
    # img = cv.imread('/content/object_detection_demo/data/raw/rings/4xnoobstacles.jpg', 0) # trainImage
    # img_threshold(img)
    # otsu_threshold(img)
    # otsu2(img)

    """# Image gradient"""


    def image_grad(img):
        # img = cv.imread('/content/object_detection_demo/data/images/train/213.jpg',0)
        laplacian = cv.Laplacian(img, cv.CV_64F)
        sobelx = cv.Sobel(img, cv.CV_64F, 1, 0, ksize=5)
        sobely = cv.Sobel(img, cv.CV_64F, 0, 1, ksize=5)
        plt.subplot(2, 2, 1), plt.imshow(img, cmap='gray')
        plt.title('Original'), plt.xticks([]), plt.yticks([])
        plt.subplot(2, 2, 2), plt.imshow(laplacian, cmap='gray')
        plt.title('Laplacian'), plt.xticks([]), plt.yticks([])
        plt.subplot(2, 2, 3), plt.imshow(sobelx, cmap='gray')
        plt.title('Sobel X'), plt.xticks([]), plt.yticks([])
        plt.subplot(2, 2, 4), plt.imshow(sobely, cmap='gray')
        plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])
        plt.show()


    def image_grad2(img):
        # img = cv.imread('/content/object_detection_demo/data/images/train/213.jpg',0)
        # Output dtype = cv.CV_8U
        sobelx8u = cv.Sobel(img, cv.CV_8U, 1, 0, ksize=5)
        # Output dtype = cv.CV_64F. Then take its absolute and convert to cv.CV_8U
        sobelx64f = cv.Sobel(img, cv.CV_64F, 1, 0, ksize=5)
        abs_sobel64f = np.absolute(sobelx64f)
        sobel_8u = np.uint8(abs_sobel64f)

        plt.subplot(1, 3, 1), plt.imshow(img, cmap='gray')
        plt.title('Original'), plt.xticks([]), plt.yticks([])
        plt.subplot(1, 3, 2), plt.imshow(sobelx8u, cmap='gray')
        plt.title('Sobel CV_8U'), plt.xticks([]), plt.yticks([])
        plt.subplot(1, 3, 3), plt.imshow(sobel_8u, cmap='gray')
        plt.title('Sobel abs(CV_64F)'), plt.xticks([]), plt.yticks([])
        plt.show()
        return sobel_8u


    def image_edge(img):
        # img = cv.imread('/content/object_detection_demo/data/images/train/213.jpg',0)
        edges = cv.Canny(img, 100, 200)
        plt.subplot(121), plt.imshow(img, cmap='gray')
        plt.title('Original Image'), plt.xticks([]), plt.yticks([])
        plt.subplot(122), plt.imshow(edges, cmap='gray')
        plt.title('Edge Image'), plt.xticks([]), plt.yticks([])
        plt.show()


    # img = cv.imread('/content/object_detection_demo/data/raw/rings/4xnoobstacles.jpg', 0) # trainImage
    # image_grad(img)
    # img = image_grad2(img)
    # image_edge(img)

    """# Ring detection using contours"""

    import copy


    def findMajorContours(im):
        height, width = im.shape[:2]
        im = np.array(im, dtype=np.uint8)

        imgray = cv.cvtColor(im, cv.COLOR_BGR2GRAY)
        ret, thresh = cv.threshold(imgray, 127, 255, 0)
        # ret, thresh = cv.threshold(imgray, 225, 255, cv.THRESH_BINARY_INV)

        contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)
        print("the number of contours: ", len(contours))
        area = []
        for i in range(0, len(contours)):
            area.append(cv.contourArea(contours[i]))

        area0 = copy.deepcopy(area)
        area.sort()
        tmp0 = area[-1]
        tmp1 = area[-2]
        tmp2 = area[-3]
        print("find contour with largest area", tmp0, tmp1, tmp2)

        t0 = [i for i, j in enumerate(area0) if j == tmp0]
        t1 = [i for i, j in enumerate(area0) if j == tmp1]
        t2 = [i for i, j in enumerate(area0) if j == tmp2]

        im2 = im.copy()

        contour_img = cv.drawContours(im, contours, -1, (0, 255, 0), 1)
        show_named_img("draw all contours", contour_img)

        # cnt = [contours[t0[0]], contours[t1[0]], contours[t2[0]]]
        cnt = contours[t0[0]]
        print(len(cnt))
        # print(cnt)
        contour_img2 = cv.drawContours(im2, cnt, -1, (0, 255, 0), 1)
        show_named_img("draw major contours", contour_img2)

        blank_image = np.zeros(shape=[height, width, 3], dtype=np.uint8)
        # white_image = 255 * np.ones(shape=[height, width, 3], dtype=np.uint8)
        # print(blank_image.shape)
        contour_img3 = cv.drawContours(blank_image, cnt, -1, (0, 255, 0), 1)
        show_named_img("draw major contours on black", contour_img3)
        return cnt


    def test_mask_orange(im):
        # cv2_imshow(im)
        im = np.array(im, dtype=np.uint8)
        # dim = (700, 700)
        # resize image
        # resized = cv.resize(im, dim, interpolation = cv.INTER_AREA)
        resized = imutils.resize(im, width=500)
        # show_named_img("resized", im)
        cropped = resized[180:260, 200:330]  # [y:y+h, x:x+w]  #(300, 220), (450, 330)
        show_named_img("cropped", cropped)
        hsv = cv.cvtColor(cropped, cv.COLOR_BGR2HSV)
        show_named_img("cropped hsv", hsv)

        # define range of orange color in HSV
        lower_orange = np.array([5, 50, 50])
        upper_orange = np.array([15, 255, 255])

        # Threshold the HSV image to get only orange colors
        mask = cv.inRange(hsv, lower_orange, upper_orange)

        # Bitwise-AND mask and original image
        res = cv.bitwise_and(cropped, cropped, mask=mask)

        show_named_img('frame', cropped)
        show_named_img('mask', mask)
        show_named_img('res', res)

        findMajorContours(res)

class DetectRingUtil:
    # ! ls -lstr /content/object_detection_demo/data/raw/rings
    # #img0 = cv.imread('/content/object_detection_demo/data/raw/rings/0xnoobstacles.jpg')
    # img0 = cv.imread('/content/object_detection_demo/data/raw/rings/1xw.obstacles.jpg')
    # img1 = cv.imread('/content/object_detection_demo/data/raw/rings/1xnoobstacles.jpg')
    # img2 = cv.imread('/content/object_detection_demo/data/raw/rings/4xnoobstacles.jpg') # trainImage
    # test_mask_orange(img2)

    """#Ring detection using edge **detection**"""
    def detect_rings(self, img):
        Util.diplay_img_data(img)
        img_resized = Util.resize(img, newWidth=720)  # Ensure the image is 720 width so the crop will work
        img_cropped = Util.crop(img_resized, (300, 220), (450, 330))  # Crop image to remove unecessary background noise
        print("cropped:")
        Util.diplay_img_data(img_cropped)
        Util.getEdges(img_cropped)

    def detect_rings_2(self, img):
        Util.diplay_img_data(img)
        img_resized = Util.resize(img, newWidth=720)  # Ensure the image is 720 width so the crop will work
        img_cropped = Util.crop(img_resized, (300, 220), (450, 330))  # Crop image to remove unecessary background noise
        print("cropped:")
        Util.diplay_img_data(img_cropped)
        contour = ContourUtil.findSignificantContour(img_cropped)
        # Draw the contour on the original image
        contourImg = np.copy(img_cropped)
        cv.drawContours(contourImg, [contour], 0, (0, 255, 0), 2, cv.LINE_AA, maxLevel=1)
        print("drawContours")
        Util.diplay_img_data(contourImg)

    def do_test(self, imgFile):
        #! ls -lstr /content/object_detection_demo/data/raw/rings
        #img0 = cv.imread('/content/object_detection_demo/data/raw/rings/0xnoobstacles.jpg')
        #img0 = cv.imread('/content/object_detection_demo/data/raw/rings/1xw.obstacles.jpg')
        img0 = cv.imread(imgFile)
        #img1 = cv.imread('/content/object_detection_demo/data/raw/rings/1xnoobstacles.jpg')
        #img2 = cv.imread('/content/object_detection_demo/data/raw/rings/4xnoobstacles.jpg') # trainImage
        #getEdges_new(img1)
        self.detect_rings(img0)
        #detect_rings_2(img1)
        #detect_rings(img0)
        #detect_rings(img1)
        #detect_rings(img2)

    """# Contour analysis"""

class ContourUtil:
    def test2(self,  im):
        im = cv.cvtColor(im, cv.COLOR_BGR2GRAY)

        ret, thresh = cv.threshold(im, 127, 255, 0)
        contours, hierarchy = cv.findContours(thresh, 1, 2)
        cnt = contours[0]
        M = cv.moments(cnt)
        print(M)


    def test_mask(self,  im):
        lower_blue = np.array([150, 150, 50])
        upper_blue = np.array([255, 255, 90])
        hsv = cv.cvtColor(im, cv.COLOR_BGR2HSV)

        # Threshold the HSV image to get only blue colors
        mask = cv.inRange(hsv, lower_blue, upper_blue)

        # Bitwise-AND mask and original image
        res = cv.bitwise_and(hsv, hsv, mask=mask)

        cv2_imshow(hsv)
        cv2_imshow(mask)
        cv2_imshow(res)


    def test_mask_orange(self, im):
        ORANGE_MIN = np.array([15, 50, 50], np.uint8)
        ORANGE_MAX = np.array([25, 255, 255], np.uint8)

        hsv = cv.cvtColor(im, cv.COLOR_BGR2HSV)
        mask = cv.inRange(hsv, ORANGE_MIN, ORANGE_MAX)
        # Bitwise-AND mask and original image
        res = cv.bitwise_and(hsv, hsv, mask=mask)
        cv2_imshow(hsv)
        cv2_imshow(mask)
        cv2_imshow(res)
        return res


    def print_all_contours(self, contours):
        print('print all contours, size ', len(contours))
        for x in contours:
            M = cv.moments(x)
            print(M)


    # https://stackoverflow.com/questions/10948589/choosing-the-correct-upper-and-lower-hsv-boundaries-for-color-detection-withcv
    def find_mask_value(self):
        red = np.uint8([[[255, 0, 0]]])
        hsv_red = cv.cvtColor(red, cv.COLOR_BGR2HSV)
        print("R: ", hsv_red)

        green = np.uint8([[[0, 255, 0]]])
        hsv_green = cv.cvtColor(green, cv.COLOR_BGR2HSV)
        print("G: ", hsv_green)

        blue = np.uint8([[[0, 0, 255]]])
        hsv_blue = cv.cvtColor(blue, cv.COLOR_BGR2HSV)
        print("B: ", hsv_blue)


    def testContours(self, im, contour_num):
        cv2_imshow(im)
        im = np.array(im, dtype=np.uint8)
        # dim = (700, 700)
        # resize image
        # resized = cv.resize(im, dim, interpolation = cv.INTER_AREA)
        resized = imutils.resize(im, width=500)
        print("resized")
        cv2_imshow(im)
        cropped = resized[140:220, 200:330]  # [y:y+h, x:x+w]  #(300, 220), (450, 330)
        imgray = cv.cvtColor(cropped, cv.COLOR_BGR2GRAY)
        ret, thresh = cv.threshold(imgray, 127, 255, 0)
        # ret, thresh = cv.threshold(imgray, 225, 255, cv.THRESH_BINARY_INV)
        # print('thresh image')
        cv2_imshow(cropped)

        contours, hierarchy = cv.findContours(imgray, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)
        print('draw contours')
        # contour_img = cv.drawContours(imgray, contours, contour_num, (0,255,0), 3)   # -1: draw all the contours; 3: the 4th contour
        contour_img = cv.drawContours(imgray, contours, contour_num, (0, 255, 0),
                                      3)  # -1: draw all the contours; 3: the 4th contour
        cv2_imshow(contour_img)

        # print_all_contours(contours)

        print('contours[0]')
        cnt = contours[0]
        M = cv.moments(cnt)
        print(M)
        area = cv.contourArea(cnt)
        perimeter = cv.arcLength(cnt, True)
        epsilon = 0.1 * cv.arcLength(cnt, True)
        approx = cv.approxPolyDP(cnt, epsilon, True)
        hull = cv.convexHull(cnt)

        x, y, w, h = cv.boundingRect(cnt)
        img_bounding = cv.rectangle(imgray, (x, y), (x + w, y + h), (0, 255, 0), 2)

        print('show bounding box')
        cv2_imshow(img_bounding)

        (x, y), radius = cv.minEnclosingCircle(cnt)
        center = (int(x), int(y))
        radius = int(radius)
        img_circle = cv.circle(imgray, center, radius, (0, 255, 0), 2)
        print('show bounding circle')
        cv2_imshow(img_circle)
        # cv.waitKey(0)
        # cv.destroyAllWindows()
        return im, imgray, contours


    # find_mask_value()
    # img = cv.imread('/content/object_detection_demo/data/raw/rings/4xnoobstacles.jpg') # trainImage
    # #res = test_mask_orange(img)
    # #testContours(res)
    # im, imgray, contours = testContours(img, 1)  # -1 to show all contours
    # #testContours(img, 3)

    # print(contours)
    import copy


    def findMajorContours(self, im):
        height, width = im.shape[:2]
        im = np.array(im, dtype=np.uint8)

        imgray = cv.cvtColor(im, cv.COLOR_BGR2GRAY)
        ret, thresh = cv.threshold(imgray, 127, 255, 0)
        # ret, thresh = cv.threshold(imgray, 225, 255, cv.THRESH_BINARY_INV)

        contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)
        print("the number of contours: ", len(contours))
        area = []
        for i in range(0, len(contours)):
            area.append(cv.contourArea(contours[i]))

        area0 = copy.deepcopy(area)
        area.sort()
        tmp0 = area[-1]
        tmp1 = area[-2]
        tmp2 = area[-3]
        print("find contour with largest area", tmp0, tmp1, tmp2)

        t0 = [i for i, j in enumerate(area0) if j == tmp0]
        t1 = [i for i, j in enumerate(area0) if j == tmp1]
        t2 = [i for i, j in enumerate(area0) if j == tmp2]

        im2 = im.copy()

        contour_img = cv.drawContours(im, contours, -1, (0, 255, 0), 1)
        print("draw all contours")
        cv2_imshow(contour_img)

        # cnt = [contours[t0[0]], contours[t1[0]], contours[t2[0]]]
        cnt = contours[t0[0]]
        print(len(cnt))
        # print(cnt)
        contour_img2 = cv.drawContours(im2, cnt, -1, (0, 255, 0), 1)
        print("draw major contours")
        cv2_imshow(contour_img2)

        blank_image = np.zeros(shape=[height, width, 3], dtype=np.uint8)
        # white_image = 255 * np.ones(shape=[height, width, 3], dtype=np.uint8)
        # print(blank_image.shape)
        contour_img3 = cv.drawContours(blank_image, cnt, -1, (0, 255, 0), 1)
        cv2_imshow(contour_img3)
        return cnt


    def contour_match(img1, img2):
        cnt1 = findMajorContours(img1)
        cnt2 = findMajorContours(img2)
        ret = cv.matchShapes(cnt1, cnt2, 1, 0.0)
        return ret

    def do_test(self):
        img = cv.imread('/content/object_detection_demo/data/images/train/190.jpg')
        img = cv.imread('/content/object_detection_demo/data/raw/rings/4xnoobstacles.jpg') # trainImage
        cnt = self.findMajorContours(img)

    """# Contour matching"""

    # print(contours)
    import copy


    def findMajorContours(im):
        height, width = im.shape[:2]
        im = np.array(im, dtype=np.uint8)

        imgray = cv.cvtColor(im, cv.COLOR_BGR2GRAY)
        ret, thresh = cv.threshold(imgray, 127, 255, 0)
        # ret, thresh = cv.threshold(imgray, 225, 255, cv.THRESH_BINARY_INV)

        contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)
        print(len(contours))
        area = []
        for i in range(0, len(contours)):
            area.append(cv.contourArea(contours[i]))

        area0 = copy.deepcopy(area)
        area.sort()
        tmp0 = area[-1]
        tmp1 = area[-2]
        tmp2 = area[-3]
        print("find contour with largest area", tmp0, tmp1, tmp2)

        t0 = [i for i, j in enumerate(area0) if j == tmp0]
        t1 = [i for i, j in enumerate(area0) if j == tmp1]
        t2 = [i for i, j in enumerate(area0) if j == tmp2]

        im2 = im.copy()

        # contour_img = cv.drawContours(im, contours, -1, (0,255,0), 1)
        # cv2_imshow(contour_img)

        # cnt = [contours[t0[0]], contours[t1[0]], contours[t2[0]]]
        cnt = contours[t0[0]]
        print(len(cnt))
        # print(cnt)
        # contour_img2 = cv.drawContours(im2, cnt, -1, (0,255,0), 1)
        # cv2_imshow(contour_img2)

        blank_image = np.zeros(shape=[height, width, 3], dtype=np.uint8)
        # white_image = 255 * np.ones(shape=[height, width, 3], dtype=np.uint8)
        # print(blank_image.shape)
        contour_img3 = cv.drawContours(blank_image, cnt, -1, (0, 255, 0), 1)
        cv2_imshow(contour_img3)
        return cnt


    def contour_match(img1, img2):
        cnt1 = findMajorContours(img1)
        cnt2 = findMajorContours(img2)
        ret = cv.matchShapes(cnt1, cnt2, 1, 0.0)
        return ret


    # img0 = cv.imread('/content/object_detection_demo/data/images/train/173.jpg')
    # img1 = cv.imread('/content/object_detection_demo/data/images/train/175.jpg')
    # img2 = cv.imread('/content/object_detection_demo/data/images/train/236.jpg')
    # ret = contour_match(img0, img1)
    # print('contour matching results: ', ret)
    # ret = contour_match(img0, img2)
    # print('contour matching results: ', ret)

    """# Histogram analysis"""

class HistogramUtil:
    # bins = np.arange(256).reshape(256,1)
    # cv2_imshow(img)
    def hist_curve(self, im):
        h = np.zeros((300, 256, 3))
        if len(im.shape) == 2:
            color = [(255, 255, 255)]
        elif im.shape[2] == 3:
            color = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]
        for ch, col in enumerate(color):
            hist_item = cv.calcHist([im], [ch], None, [256], [0, 256])
            cv.normalize(hist_item, hist_item, 0, 255, cv.NORM_MINMAX)
            hist = np.int32(np.around(hist_item))
            pts = np.int32(np.column_stack((bins, hist)))
            cv.polylines(h, [pts], False, col)
        y = np.flipud(h)
        return y


    def hist_lines(self, im):
        h = np.zeros((300, 256, 3))
        if len(im.shape) != 2:
            print("hist_lines applicable only for grayscale images")
            # print("so converting image to grayscale for representation"
            im = cv.cvtColor(im, cv.COLOR_BGR2GRAY)
        hist_item = cv.calcHist([im], [0], None, [256], [0, 256])
        cv.normalize(hist_item, hist_item, 0, 255, cv.NORM_MINMAX)
        hist = np.int32(np.around(hist_item))
        for x, y in enumerate(hist):
            cv.line(h, (x, 0), (x, y), (255, 255, 255))
        y = np.flipud(h)
        return y


    def hist_plot(self, im):
        plt.hist(im.ravel(), 256, [0, 256]);
        plt.show()
        color = ('b', 'g', 'r')
        for i, col in enumerate(color):
            histr = cv.calcHist([img], [i], None, [256], [0, 256])
            plt.plot(histr, color=col)
            plt.xlim([0, 256])
        plt.show()


    def hist_equalization(self, im):
        hist, bins = np.histogram(im.flatten(), 256, [0, 256])
        cdf = hist.cumsum()
        cdf_normalized = cdf * float(hist.max()) / cdf.max()
        plt.plot(cdf_normalized, color='b')
        plt.hist(im.flatten(), 256, [0, 256], color='r')
        plt.xlim([0, 256])
        plt.legend(('cdf', 'histogram'), loc='upper left')
        plt.show()

        # create a CLAHE object (Arguments are optional).
        clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        gray_image = cv.cvtColor(im, cv.COLOR_BGR2GRAY)
        cl1 = clahe.apply(gray_image)
        cv2_imshow(cl1)


    def hist_plot2d(self, im):
        hsv = cv.cvtColor(im, cv.COLOR_BGR2HSV)
        hist = cv.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])
        plt.plot(hist)

        hsv = cv.cvtColor(im, cv.COLOR_BGR2HSV)
        hist, xbins, ybins = np.histogram2d(h.ravel(), s.ravel(), [180, 256], [[0, 180], [0, 256]])
        plot.plot(hist)


    # img = cv.imread('/content/object_detection_demo/data/images/train/190.jpg')
    #
    # #hist_plot2d(img)
    # hist_equalization(img)
    # #hist_backproj2()

    """# Histogram matching"""


    def hist_match(self, img1, img2):
        hsv = cv.cvtColor(img1, cv.COLOR_BGR2HSV)

        hsvt = cv.cvtColor(img2, cv.COLOR_BGR2HSV)

        # calculating object histogram
        roihist = cv.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])

        # normalize histogram and apply backprojection
        cv.normalize(roihist, roihist, 0, 255, cv.NORM_MINMAX)
        dst = cv.calcBackProject([hsvt], [0, 1], roihist, [0, 180, 0, 256], 1)

        # Now convolute with circular disc
        disc = cv.getStructuringElement(cv.MORPH_ELLIPSE, (5, 5))
        cv.filter2D(dst, -1, disc, dst)

        # threshold and binary AND
        ret, thresh = cv.threshold(dst, 50, 255, 0)
        thresh = cv.merge((thresh, thresh, thresh))
        res = cv.bitwise_and(img2, thresh)

        res = np.vstack((img2, thresh, res))
        cv2_imshow(res)


    def hist_match3(self):
        src_base = cv.imread('/content/object_detection_demo/data/images/train/181.jpg')
        src_test1 = cv.imread('/content/object_detection_demo/data/images/train/182.jpg')
        src_test2 = cv.imread('/content/object_detection_demo/data/images/train/183.jpg')
        if src_base is None or src_test1 is None or src_test2 is None:
            print('Could not open or find the images!')
            exit(0)
        ## [Load three images with different environment settings]

        ## [Convert to HSV]
        hsv_base = cv.cvtColor(src_base, cv.COLOR_BGR2HSV)
        hsv_test1 = cv.cvtColor(src_test1, cv.COLOR_BGR2HSV)
        hsv_test2 = cv.cvtColor(src_test2, cv.COLOR_BGR2HSV)
        ## [Convert to HSV]

        ## [Convert to HSV half]
        hsv_half_down = hsv_base[hsv_base.shape[0] // 2:, :]
        ## [Convert to HSV half]

        ## [Using 50 bins for hue and 60 for saturation]
        h_bins = 50
        s_bins = 60
        histSize = [h_bins, s_bins]

        # hue varies from 0 to 179, saturation from 0 to 255
        h_ranges = [0, 180]
        s_ranges = [0, 256]
        ranges = h_ranges + s_ranges  # concat lists

        # Use the 0-th and 1-st channels
        channels = [0, 1]
        ## [Using 50 bins for hue and 60 for saturation]

        ## [Calculate the histograms for the HSV images]
        hist_base = cv.calcHist([hsv_base], channels, None, histSize, ranges, accumulate=False)
        cv.normalize(hist_base, hist_base, alpha=0, beta=1, norm_type=cv.NORM_MINMAX)

        hist_half_down = cv.calcHist([hsv_half_down], channels, None, histSize, ranges, accumulate=False)
        cv.normalize(hist_half_down, hist_half_down, alpha=0, beta=1, norm_type=cv.NORM_MINMAX)

        hist_test1 = cv.calcHist([hsv_test1], channels, None, histSize, ranges, accumulate=False)
        cv.normalize(hist_test1, hist_test1, alpha=0, beta=1, norm_type=cv.NORM_MINMAX)

        hist_test2 = cv.calcHist([hsv_test2], channels, None, histSize, ranges, accumulate=False)
        cv.normalize(hist_test2, hist_test2, alpha=0, beta=1, norm_type=cv.NORM_MINMAX)
        ## [Calculate the histograms for the HSV images]

        ## [Apply the histogram comparison methods]
        for compare_method in range(4):
            base_base = cv.compareHist(hist_base, hist_base, compare_method)
            base_half = cv.compareHist(hist_base, hist_half_down, compare_method)
            base_test1 = cv.compareHist(hist_base, hist_test1, compare_method)
            base_test2 = cv.compareHist(hist_base, hist_test2, compare_method)

            print('Method:', compare_method, 'Perfect, Base-Half, Base-Test(1), Base-Test(2) :', \
                  base_base, '/', base_half, '/', base_test1, '/', base_test2)
        ## [Apply the histogram comparison methods]


    # not working
    def hist_backproj(self, img1, img2):
        hsv1 = cv.cvtColor(img1, cv.COLOR_BGR2HSV)

        # target is the image we search in
        hsvt = cv.cvtColor(img2, cv.COLOR_BGR2HSV)

        # Find the histograms using calcHist. Can be done with np.histogram2d also
        M = cv.calcHist([hsv1], [0, 1], None, [180, 256], [0, 180, 0, 256])
        I = cv.calcHist([hsvt], [0, 1], None, [180, 256], [0, 180, 0, 256])

        h, s, v = cv.split(hsvt)
        B = R[h.ravel(), s.ravel()]
        B = np.minimum(B, 1)
        B = B.reshape(hsvt.shape[:2])

        disc = cv.getStructuringElement(cv.MORPH_ELLIPSE, (5, 5))
        cv.filter2D(B, -1, disc, B)
        B = np.uint8(B)
        cv.normalize(B, B, 0, 255, cv.NORM_MINMAX)
        ret, thresh = cv.threshold(B, 50, 255, 0)
        return ret


    # working version
    def do_test(self):
        roi = cv.imread('/content/object_detection_demo/data/images/train/stone_background.jpg')  # trainImage
        hsv = cv.cvtColor(roi, cv.COLOR_BGR2HSV)
        target = cv.imread('/content/object_detection_demo/data/images/train/200.jpg')
        hsvt = cv.cvtColor(target, cv.COLOR_BGR2HSV)
        # calculating object histogram
        roihist = cv.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])
        # normalize histogram and apply backprojection
        cv.normalize(roihist, roihist, 0, 255, cv.NORM_MINMAX)
        dst = cv.calcBackProject([hsvt], [0, 1], roihist, [0, 180, 0, 256], 1)
        # Now convolute with circular disc
        disc = cv.getStructuringElement(cv.MORPH_ELLIPSE, (5, 5))
        cv.filter2D(dst, -1, disc, dst)
        # threshold and binary AND
        ret, thresh = cv.threshold(dst, 50, 255, 0)
        thresh = cv.merge((thresh, thresh, thresh))
        res = cv.bitwise_and(target, thresh)
        res = np.vstack((target, thresh, res))
        cv2_imshow(res)


    # hist_match3()
    # hist_match(img_ref, img2)
    # hist_backproj2()

    """# Template Matching
    
    """

class TemplateUtil:
    def template_match(self):
        img = cv.imread('/content/object_detection_demo/data/images/train/messi5.jpg', 0)
        # img = cv.imread('/content/object_detection_demo/data/images/train/200.jpg',0)
        img2 = img.copy()
        template = cv.imread('/content/object_detection_demo/data/images/train/messi_template.jpg', 0)
        # template = cv.imread('/content/object_detection_demo/data/images/train/skystone_clipped.jpg',0)
        w, h = template.shape[::-1]

        # All the 6 methods for comparison in a list
        methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',
                   'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']

        for meth in methods:
            img = img2.copy()
            method = eval(meth)

            # Apply template Matching
            res = cv.matchTemplate(img, template, method)
            min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)

            # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum
            if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:
                top_left = min_loc
            else:
                top_left = max_loc
            bottom_right = (top_left[0] + w, top_left[1] + h)

            cv.rectangle(img, top_left, bottom_right, 255, 2)

            plt.subplot(121), plt.imshow(res, cmap='gray')
            plt.title('Matching Result'), plt.xticks([]), plt.yticks([])
            plt.subplot(122), plt.imshow(img, cmap='gray')
            plt.title('Detected Point'), plt.xticks([]), plt.yticks([])
            plt.suptitle(meth)

            plt.show()


    # not sure if how it works
    def template_multi_match(self):
        img_rgb = cv.imread('/content/object_detection_demo/data/images/train/messi5.jpg')
        # img_rgb = cv.imread('/content/object_detection_demo/data/images/train/200.jpg')
        img_gray = cv.cvtColor(img_rgb, cv.COLOR_BGR2GRAY)

        template = cv.imread('/content/object_detection_demo/data/images/train/messi_template.jpg', 0)
        # template = cv.imread('/content/object_detection_demo/data/images/train/skystone_clipped.jpg',0)

        w, h = template.shape[::-1]

        # All the 6 methods for comparison in a list
        methods = ['cv.TM_CCOEFF']

        for meth in methods:
            method = eval(meth)
            res = cv.matchTemplate(img_gray, template, method)
            threshold = 0.5
            loc = np.where(res >= threshold)
            for pt in zip(*loc[::-1]):
                cv.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0, 0, 255), 2)

            cv2_imshow(img_rgb)

        # #template_multi_match()


    # template_match()
    #
    # """# Feature matching (SIFT)


    # SIFT issue; not working
    def feature_match(self):
        img1 = cv.imread('/content/object_detection_demo/data/images/train/box.png', 0)  # queryImage
        img2 = cv.imread('/content/object_detection_demo/data/images/train/box_in_scene.png', 0)  # trainImage

        # Initiate SIFT detector
        sift = cv.SIFT()

        # find the keypoints and descriptors with SIFT
        kp1, des1 = sift.detectAndCompute(img1, None)
        kp2, des2 = sift.detectAndCompute(img2, None)

        # FLANN parameters
        FLANN_INDEX_KDTREE = 0
        index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
        search_params = dict(checks=50)  # or pass empty dictionary

        flann = cv.FlannBasedMatcher(index_params, search_params)

        matches = flann.knnMatch(des1, des2, k=2)

        # Need to draw only good matches, so create a mask
        matchesMask = [[0, 0] for i in xrange(len(matches))]

        # ratio test as per Lowe's paper
        for i, (m, n) in enumerate(matches):
            if m.distance < 0.7 * n.distance:
                matchesMask[i] = [1, 0]

        draw_params = dict(matchColor=(0, 255, 0),
                           singlePointColor=(255, 0, 0),
                           matchesMask=matchesMask,
                           flags=0)

        img3 = cv.drawMatchesKnn(img1, kp1, img2, kp2, matches, None, **draw_params)

        plt.imshow(img3, ), plt.show()

def test_colab():
    #Util.whoami()
    input_file = GoogleDrive().getDrivePath() + "py_images\\4xw.obstacles.jpg"
    Util.show_named_img(input_file)

def main():
    #test_colab()
    ringDection = DetectRingUtil()
    ringDection.do_test("py_images\\4xw.obstacles.jpg")

if __name__ == "__main__":
    main()


